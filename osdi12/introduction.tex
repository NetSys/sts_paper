Given their critical role in enterprises, one might expect that networks
would come with a well-developed suite of troubleshooting tools. However,
the unfortunate truth is that {\tt traceroute}, developed in 1987~\cite{traceroute},
remains the network administrator's most sophisticated diagnostic mechanism. This reflects
the lack of structure in network control planes, which are an ad hoc mixture of
distributed protocols and manual configuration that directly manipulate the forwarding tables; it is hard to tell what is broken
when desired behavior is only implicitly expressed in the routing entries themselves.

In this respect, the emergence of Software-Defined
Networks (SDN) provides both an opportunity and a challenge. Moving control logic out of hardware and into software 
enables enables concise policy specifications and significantly more sophisticated testing and troubleshooting tools. Moreover, since SDN
is still in its infancy (compared to traditional networking approaches), we as a community have an opportunity to make diagnostic tools
a more integral part of the overall design process. The challenge is that although SDN's goal is to simplify the
{\em management} of networks, the SDN software stack itself is a complex distributed system, operating in asynchronous, heterogeneous, and failure-prone environments.
In this paper we present our approach to troubleshooting bugs in SDN control
software, a tool called \projectname{}.

It is important to place this work in context and scope the problem we are
attacking. First, \projectname{} is a troubleshooting tool, not a debugger; by
this we mean that \projectname{} helps identify and localize network
problems (what, where, and when?), but it does not help identify exactly which
line of code causes the error (why?). Second, \projectname{} is focused on the
system software layer of the SDN stack (described in the next section). While progress has been made in troubleshooting control
applications that run on top of the SDN platform~\cite{nice} and in troubleshooting the forwarding tables in the physical switches~\cite{anteater,hsa}, we  
are not aware of previous troubleshooting work that focuses on the SDN
platform itself; to the best of our knowledge, painstaking analysis of detailed logs is the current state-of-the-art in SDN platform troubleshooting. 

\projectname{} enhances the troubleshooting process by localizing the root cause
of network problems along three dimensions: what network problems exist at a
given point in time, where in the control software the problems first developed, and when the triggering event occurred. To accomplish this, 
\projectname{} employs two techniques:

\noindent{\bf Correspondence Checking}. We observe that the structure of the
SDN platform (as we discuss in the next section) enables a straightforward algorithm for
checking that control applications' policies are implemented correctly in
the physical network. Our algorithm enumerates all policy-violations
(\ie{}, any instance where the high-level policies are not properly
implemented by the SDN platform) present in the network at a given point in
time, providing a crisp determination of the range of inputs 
and the system component(s) responsible for the fault.
% TODO: point out that correspondence checking tells us ALL possible inputs
% that would be effected by the poliy-violation? This is what we mean by
% "providing a crisp determination"

\noindent{\bf \Simulator{}.} \projectname{} can replay the execution of the SDN platform against
a stream of network events (e.g., link failures). This allows us to (i) distinguish between policy-violations that are harmless and quickly heal and those that are persistent or pernicious, and (ii) identify the minimal set of events that triggered
the policy-violation.

In combination, correspondence checking and \simulator{} programmatically localize software-faults in the SDN platform.
With \projectname{}, operators and developers are free to focus their efforts
on debugging the code itself, without needing to 
diagnose the symptoms in the first place.
% This represents an improvement over the state-of-the-art SDN troubleshooting
% practices

In evaluating \projectname{} on
three popular SDN platforms---Frenetic, Floodlight, and POX---we find \colin{N} bugs,
including isolation breaches,
faulty failover logic, and consistency problems between replicated
controllers. We further demonstrate the feasibility of deploying
\projectname{} on production networks,
finding that our tools can enumerate all policy-violations in 
simulated networks exceeding 100,000 hosts in under \colin{N} seconds.

The rest of this paper is organized as follows. In \S\ref{sec:overview},
we present an overview of the SDN stack and its failure modes.
In \S\ref{sec:approach} we present correspondence checking and
\simulator{} in detail. We discuss the design of \projectname{} in
\S\ref{sec:architecture}. In \S\ref{sec:evaluation} we present
\colin{N} bugs found by \projectname{}, as well as a performance evaluation.
Finally, in \S\ref{sec:related_work} we discuss related work,
and in \S\ref{sec:conclusion} we conclude.

\eat{
\subsection{\colin{Feedback from Kay et al.}}
\begin{itemize}
\item Not sure that OSDI PC members will understand the subtleties of this statement: ``it is hard to tell what is broken when the goals are only implicitly expressed in the flow entries themselves.''
\item I think we should push a little harder on emphasizing that the bugs are really nasty, and fundamental to the distributed nature of the system. "may have bugs" seems a little weak.
\item We should make it very clear how our tools are an improvement over the status quo (log analysis). In particular, we automatically localize the (i) layer, and (ii) minimal causal set of events responsible for an error.
\item \simulator{} does two things: find the minimal causal set, {\bf and}
differentiates benign from pernicious. Only one of these points was clear, not
both.
\item The Google quote seems to indicate that the problem has already been solved!
\item Along a similar vein, the point about ``the SDN platform will eventually
become stable'' makes it seems like these problems aren't fundamental. But
these problems are fundamental! How will the community view this paper in 10
years?
\item The reader doesn't walk away from this problem thinking ``This problem
seems really heard!''. What are the specific bugs this framework addresses?
Also, make it clear why this problem is important! If Pepsi knows that
Coca-cola might be able to snoop on their traffic, we've lost huge \$\$\$.
\item Don't frame ourselves just against log analysis. Make 
the shortcomings of the status quo very clear, and be very precise about how
we address those shortcoming. (Why aren't traditional distributed systems
techniques apropro? Why is static checking of a single layer insufficient? How
is \simulator{} different than traditional replay debugging?)
\item Would be cool to have numbers on how many log events developers have to
step through today.
\item Would also be cool to have numbers on how many benign policy-violations
there are at a given point (say, in POX).
\item ``Policy-violation'' wasn't well-defined.
\item The introduction (prose) was too dense. Frame the problem in terms that
the reader understands. Get them thinking about the problem right off the bat.
Then lead them through our reasoning of how we came to the solution. Present
a straw-man solution, and show why that doesn't work. This way
the reader is much more engaged -- the reader should ``nod along''.
\item What exactly are we simulating? Hardware faults? Misconfigurations?
(answer: all of the above)
\item How exactly does correspondence checking provide a crisp determination of the scope of a policy-violation in the
network as well as the range of inputs that produce it? (answer: you start off
with a customer complaint, ``A can't ping B''. Correspondence checking tells
you all possible inputs that would experience the blackhole, and what parts of
the network are effected)
\item ``Stack'' connotes TCP/IP. Maybe use ``Platform'' instead?
\item ``Fault'' connotes hardware failure. Maybe use ``Software Fault''
\item Cite Frenetic, POX, Floodlight?
\item What does \projectname{} stand for?
\end{itemize}
}
