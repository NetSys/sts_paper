This work extends a growing literature on troubleshooting tools for
Software-Defined Networks.
    
The work most closely related to ours is NICE~\cite{nice}. NICE combines concolic execution
and model checking to automate the process of testing NOX applications. This enables one to catch bugs before
they are deployed.  

Our approach and NICE complement each other in several ways.  First, NICE's systematic exploration of failure orderings 
is potentially of great use for finding corner-case errors, which we could then add to our regression suite. NICE may also be applied directly to the code-base of the SDN platform, but in the case that only a subset
of all possible code-paths in the SDN platform can be model-checked due to state-space explosion; 
our mechanisms allows users to troubleshoot errors 
{\it post-hoc} after they are observed in production, so we can find bugs that might be missed due to truncating the state-space exploration.
In complement to NICE, correspondence checking helps developers isolate the
specific component of the SDN platform responsible for an error, without needing to specify invariants.

Focusing on the physical network, Anteater~\cite{anteater} and HSA~\cite{hsa}
are alternative approaches to statically checking invariants in the
configuration of switches and routers. Both take take as input a snapshot of
the FIB of each network device. To check invariants, Anteater generates a set of constraint functions and feeds them through a SAT
solver, while HSA defines an algebra for virtual packets and
their transformation through the network. We leverage the HSA work in \projectname{}, and our simulator allows us to detect policy-violations not just in a given set of tables but what tables are produced by a wide range of scenarios. \

Also focusing on the physical network, OFRewind~\cite{ofrewind} develops
record and replay techniques for the control plane of OpenFlow networks.
Unlike \simulator, OFRewind focuses specifically on OpenFlow
interactions, while we focus on more course-grained replay of
failures and topology changes. Running replay within a simulator also allows
us to manually modify the execution of the system, rather than playing a
static recording. 

Another line of work aims to prevent bugs from being introduced in the first
place. Frenetic~\cite{frenetic} presents a language-based approach to building
robust SDN applications. By providing a specialized programming model,
 Frenetic helps developers avoid writing common classes of
bugs, such as `composition errors' where installed flow entries override each other.
Reitblatt et al.~\cite{consistentupdates} developed a technique for ensuring
consistent routing updates, guaranteeing that all switches in the network either route
a given packet under the new configuration or under the old configuration,
but not both. These abstractions are valuable for preventing common, difficult errors
in platform logic.

Several other network simulators exist for testing SDN controllers. Mininet is a 
platform for emulating OpenFlow switches and hosts within a single
 VM~\cite{Lantz:2010:NLR:1868447.1868466}. The ns-series of network simulators
provides a general framework for testing new protocols, topologies,
and traffic mixes~\cite{ns3}. We found that these existing simulators did
not provide sufficient support for the corner-cases situations which are the
focus of our work, such as failures and VM migration.

Many of our ideas originate from the literature on troubleshooting general
distributed systems. WiDS checker introduced the notion of recording
production executions to be later replayed and verified in a controlled simulation.
Pip~\cite{pip} defines a DSL and collection of annotation tools to
reason about causal paths throughout the execution of the
distributed system. Finally, end-to-end tracing
frameworks such as X-Trace~\cite{Fonseca:2007:XPN:1973430.1973450} and 
Pinpoint~\cite{Chen02pinpoint:problem} provide a framework for tracing requests throughout 
a distributed system in order to infer correctness errors between layers and
across components. Our work solves a more constrained problem; we leverage
the structure of the SDN stack to enable a simple notion of platform
correctness. In addition, these systems assume that invariants should hold at
all times; we observe that in an eventually-consistent system such as SDN,
transient policy-violations are inevitable. We built \simulator{} to help troubleshooters
differentiate ephemeral from persistent errors. 

% If we manage to run multiple applications by Monday, we should cite papers
% on consistency and cross-layer debugging:
%X-Trace~\cite{xtrace}
% Vector Clocks
% Onix
% Virtualization definitely won't happen by Monday. But, papers include
% Martin's presto '10 paper 'Virtualizaing the Network Forwarding Plane'

