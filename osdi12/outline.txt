
Abstract

1. Intro

- Status quo is to painstakingly look at logs. 
- SDN provides layers of abstraction.
- Our focus is on debugging the abstractions provided by the platform.
  * Assume the application is correct
  * Check correspondence between app + other layers
  * Checking correspondence once isn't enough => need (sophisticated) test harness

- Failures and updates are what make consistency hard! Normal running conditions are pretty tame.

2. SDN Overview

(intersperse related work, "fence posting" ourselves from the others)

- Description of Platform: 
   * Reactive vs. Proactive flow entry installation
   * Distributed controllers
   * Physical, logical, and virtual layers

- Taxonomy of failure modes introduced by these abstractions (Google Doc)

3. Architecture

- High level description: correspondence + test harness
- Walk through a normal transient miscorrespondence case
- Walk through a pernicious transient miscorrespondence case
- Walk through a persistent miscorrespondence case
  * throughout examples, explain how test harness et. el. are useful

- Implementation details

4. Evaluation

- Caveat: not evaluating on a commercial code base, (since NOX doesn't have layering, and we don't have access to Onix)

- Is it general enough? => walk through failure cases described in Section 2, and show how debugger helps with them

- Does it find bugs? => run on third party application (Murphy's code?)

- Does it have reasonable overhead? => Graph of performance for interactive test harness use

5. Related work

- Language-level bug prevention (Frentic et. al)
- Application-level static analysis (NICE et. al.)
- Data-plane static analysis (Anteater, Header space analysis)
- Test harnesses (Mininet)
- Replay debugging and general distributed systems debugging => We constrain our problem domain, thereby making the problem somewhat more tractable

6. Conclusion
