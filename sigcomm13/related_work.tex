We categorize related work according to field:

\noindent{\bf Software Engineering}
All of the below focus on single programs (possibly multi-threaded, but always single-core)
\begin{itemize}
\item Delta Debugging: given a failing test case and an input file (e.g. HTML page), run modified binary search on the input file to find the minimum subset that triggers the failure. We attempt to solve the same problem in a distributed setting, where the input is spread across time and space. Zeller also applied DD to a multi-threaded (single-core) programs to identify the minimum set of thread switches from a schedule that reproduces a race condition. DD still hasn't been applied across space (machines).
\item Sherlog: given a program and production logs that ended in a failure, find the minimum subset of the program execution (both control-flow and data-values) that lead up to the failure. Don't re-execute the program! Statically analyze the code and the log statements preceding the crash.
\item Treating bugs like allergies: on encountering a crash, back up to a checkpoint, fuzz the environment (e.g., thread scheduling), and restart the program. Helps with availability, but doesn't help with troubleshooting! We focus on identifying the inputs that caused the bug, so that a developer can fix it.
\item Execution Synthesis (epfl): given a program and a bug report, find an
execution (thread schedule) that leads up to that failure. Re-executes the
program (unlike Sherlog), but doesn't require runtime recording of any sort
(uses symbolic execution instead).
\item The concept of `fingerprinting' has come up before, in a rather different context (really, they're breadcrumbs, not fingerprints): Zamfir included stack traces in core dumps to make it easier to figure out what causes deadlocks.
\end{itemize}

\noindent{\bf Systems and Networking}
\begin{itemize}
\item OFRewind: Deterministic replay techniques such as OFRewind allow developers to interactively prune the inputs that lead up to errant behavior. Our technique automates the process of identifying faulty inputs from large input logs.
\item Tracing tools: allow developers to step through dataplane traces (NDB), or control plane traces (X-trace) to diagnose performance and correctness problems. We focus on automating the triage process.
\item Causal path tools: such as Pip instrument general-purpose distributed systems
with code to record, display, and check invariants on causal paths throughout
live executions. sts observes the causal behavior of the
distributed system in a simulated environment, enabling us to iteratively prune extraneous input events.
\item Root cause analysis techniques seek to identify the minimum set of failed
components (e.g. link failures) needed to explain a collection of alarms. Rather than
focusing on individual component failures, we seek to minimize inputs that affect the behavior
of the overall distributed system.
\item Debug Determinism: suggests that replay debuggers should not seek to achieve perfect fidelity -- the utility of the replay can still be high, even if all failure modes can't be reproduced. Our approach follows this argument: can't catch everything, but it's still useful!
\end{itemize}


\noindent{\bf Programming Languages}
\begin{itemize}
\item Model checkers: such as NICE enumerate all possible code paths taken by control software (NOX)
and identify concrete inputs (e.g.control message orderings) that cause
the network to enter invalid configurations. NICE works well for small
control programs and a small number of machines, but suffers from exponential
state explosion when run on large systems. For example, NICE took 30 hours to
model check a network with two switches, two hosts, the MAC-learning
control program (98 LoC), and five concurrent
messages between the hosts. We chose to avoid state-space explosion by analyzing logs post-hoc, after they have been observed in production.
\item Program Slicing (Mark Weiser, â€˜81): given a program and a line of code
within that program, find the subset of the program that could possibly affect
the result of that line of code. Achieve this by reasoning about control +
data flow. We want to do the same thing, except that the `program' is replaced
by Dist'Sys events, and `line of code' is replaced by a network misconfiguration.
\end{itemize}


% ----------------------------------------- %
%          OLD TEXT
\eat{

\colin{TODO: cite ndb + Nick's keynote}

\colin{Reviewer OD: read Knowledge Plane For The
Internet~\cite{Clark:2003:KPI:863955.863957}}

\colin{Reviewer OA: tools already exist that systematically exercise the
behavior of a good part of the network (if not the whole network).}

%-- Program Slicing --

The delta debugging algorithm~\cite{Zeller:2002:SIF:506201.506206} seeks to solve
a problem that is exactly analogous to ours on a single machine: given input that causes a test case
to fail, what is the minimum subset of the input that still produces the failure?
We apply the same reasoning to a distributed system.

%-- Deterministic Replay (OFRewind) --

Deterministic replay techniques such as OFRewind~\cite{ofrewind}
are designed to allow developers to interactively prune
the inputs that lead up to errant behavior. We present an algorithm that
automates this process.

%-- Model checking (NICE): --

NICE~\cite{nice} combines model checking with concolic execution
to enumerate all possible code paths taken by control software (NOX)
and identify concrete inputs (\eg{} control message orderings) that cause
the network to enter invalid configurations. NICE works well for small
control programs and a small number of machines, but suffers from exponential
state explosion when run on large systems. For example, NICE took 30 hours to
model check a network with two switches, two hosts, the MAC-learning
control program (98 LoC), and five concurrent
messages between the hosts~\cite{nice}. We chose to avoid state-space explosion by analyzing logs
{\em post-hoc}, after they have been observed in production.

%-- Invariant Checking? --

\eat{
Invariant checking tools such as Anteater~\cite{anteater} and HSA~\cite{hsa}
detect problems in the dataplane. We leverage invariant checking tools
to distinguish inputs that are necessary for reproducing a given invariant violation.
}

%-- Root cause analysis? --

Root cause analysis techniques~\cite{577079} seek to identify the minimum set of failed
components (\eg{} link failures) needed to explain a collection of alarms. Rather than
focusing on individual component failures, we seek to minimize inputs that affect the behavior
of the overall distributed system.

%-- Distributed Systems debuggers --

Pip~\cite{pip} is a framework for instrumenting general-purpose distributed systems
with code to record, display, and check invariants on causal paths throughout
live executions. \Simulator{} observes the causal behavior of the
distributed system in a simulated environment, enabling us to iteratively prune extraneous input events.

% ------------ OLD -----------

\eat{
This work extends a growing literature on troubleshooting tools for
Software-Defined Networks.

The work most closely related to ours is NICE~\cite{nice}. NICE combines concolic execution
and model checking to automate the process of testing NOX applications. This enables one to catch bugs before
they are deployed.

Our approach and NICE complement each other in several ways.  First, NICE's systematic exploration of failure orderings
is potentially of great use for finding corner-case errors, which we could then add to our regression suite. NICE may also be applied directly to the code-base of the SDN platform, but in the case that only a subset
of all possible code-paths in the SDN platform can be model-checked due to state-space explosion;
our mechanisms allows users to troubleshoot errors
{\it post-hoc} after they are observed in production, so we can find bugs that might be missed due to truncating the state-space exploration.
In complement to NICE, correspondence checking helps developers isolate the
specific component of the SDN platform responsible for an error, without needing to specify invariants.

Focusing on the physical network, Anteater~\cite{anteater} and HSA~\cite{hsa}
are alternative approaches to statically checking invariants in the
configuration of switches and routers. Both take take as input a snapshot of
the FIB of each network device. To check invariants, Anteater generates a set of constraint functions and feeds them through a SAT
solver, while HSA defines an algebra for virtual packets and
their transformation through the network. We leverage the HSA work in \projectname{}, and our simulator allows us to detect correctness violations not just in a given set of tables but what tables are produced by a wide range of scenarios. \

Also focusing on the physical network, OFRewind~\cite{ofrewind} develops
record and replay techniques for the control plane of OpenFlow networks.
Unlike \simulator, OFRewind focuses specifically on OpenFlow
interactions, while we focus on more course-grained replay of
failures and topology changes. Running replay within a simulator also allows
us to manually modify the execution of the system, rather than playing a
static recording.

Another line of work aims to prevent bugs from being introduced in the first
place. Frenetic~\cite{frenetic} presents a language-based approach to building
robust SDN applications. By providing a specialized programming model,
 Frenetic helps developers avoid writing common classes of
bugs, such as `composition errors' where installed flow entries override each other.
Reitblatt et al.~\cite{consistentupdates} developed a technique for ensuring
consistent routing updates, guaranteeing that all switches in the network either route
a given packet under the new configuration or under the old configuration,
but not both. These abstractions are valuable for preventing common, difficult errors
in platform logic.

Several other network simulators exist for testing SDN controllers. Mininet is a
platform for emulating OpenFlow switches and hosts within a single
 VM~\cite{Lantz:2010:NLR:1868447.1868466}. The ns-series of network simulators
provides a general framework for testing new protocols, topologies,
and traffic mixes~\cite{ns3}. We found that these existing simulators did
not provide sufficient support for the corner-cases situations which are the
focus of our work, such as failures and VM migration.

Many of our ideas originate from the literature on troubleshooting general
distributed systems. WiDS checker introduced the notion of recording
production executions to be later replayed and verified in a controlled simulation~\cite{Liu07widschecker:}.
Pip~\cite{pip} defines a DSL and collection of annotation tools to
reason about causal paths throughout the execution of the
distributed system. Finally, end-to-end tracing
frameworks such as X-Trace~\cite{Fonseca:2007:XPN:1973430.1973450} and
Pinpoint~\cite{Chen02pinpoint:problem} provide a framework for tracing requests throughout
a distributed system in order to infer correctness errors between layers and
across components. Our work solves a more constrained problem; we leverage
the structure of the SDN stack to enable a simple notion of platform
correctness. In addition, these systems assume that invariants should hold at
all times; we observe that in an eventually-consistent system such as SDN,
transient correctness violations are inevitable. We built \simulator{} to help troubleshooters
differentiate ephemeral from persistent errors.

% If we manage to run multiple applications by Monday, we should cite papers
% on consistency and cross-layer debugging:
%X-Trace~\cite{xtrace}
% Vector Clocks
% Onix
% Virtualization definitely won't happen by Monday. But, papers include
% Martin's presto '10 paper 'Virtualizaing the Network Forwarding Plane'

}
}
