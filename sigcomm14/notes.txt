Flow:
 - Consider external events generated by test infrastructure.
 - Introduce invariants, replay, reproduction.
 - Our goal is to minimize these external events and still trigger the bug.
   Formally, we're looking for an MCS.
 - To do this we'll employ a minimization algorithm to test subsequences of
   the trace. To get a minimal result we need to make sure we reproduce the bug
   whenever possible for a given subsequence.
 - If we just replay subsequences of those, with the same relative timing, and it works,
   then we say the system is serializable.
   QuickCheck assumes this [including the PULSE paper?]
 - But that doesn't always work. If the system isn't serializable, then
   changing the inputs may perturb the way the system reacts to events, e.g.
   it might read clock values, and react differently as a result of different
   timings. We need to consider internal events.
 - The information encoded in those internal events determines what we do next.
 - Suppose the internal information is complete, in the sense that it includes
   the thread schedule, and recordings of every I/O request/response for each
   process, such that (assuming we can control the thread schedule) we have everything
   we need to deterministically replay the execution.
 - We could then do what Zeller et al do: minimize the tread schedule.
   A few problems with this:
   - The inputs need to be fixed, because if they remove an I/O event, then
     their trace *may* not contain all the information they need to proceed with
     replay. Consider that by removing a message receive event, the state
     machine might take a different code path. At some point along the divergent
     path, the process might initiate an unexpected I/O event, e.g. reading
     from a clock. Now the replayer doesn't know how to respond to this
     request. Worse yet is that the divergent process may affect the thread
     schedule that the replayer is trying carefully to control, for example by
     descheduling itself at a different point than it did originally.
     Now the recorded thread schedule is rendered useless for this thread,
     since the original preemption points may no longer be executed.
     Due to these issues they consider any divergent path invalid, and thereby
     miss out on input minimization opportunities. In other words, they can't
     find bugs in states that are equivalent but not equal to the original
     final state [diagram]
   - Consequently, their goal is only to minimizing # of thread context switches, but not #
     of inputs.
   - That said, they can modify inputs in one way: they can truncate the thread
     schedule (Sen's "Remove Last" step) and see if the violation still
     appears. But that's not really perturbing the inputs per se, it's really
     just deciding to exit early. They can't remove any I/O events from the
     beginning of the trace.
 - Consider the keyword "may" above. Papers on program flow tracing (X
   Zhang, X Zhang) tighten that up by tracking individual instructions in the
   execution, and using this tracing to compute program flow dependencies.
   They then try to identify I/O events where
   they can prove that, if removed, the (non-extraneous) path taken by the
   state machine will not stray. They make those inferences by following every
   instruction (transition) taken by the state machine along the path, and
   then statically/dynamically computing program flow dependencies. They can
   remove I/O events from anywhere in the trace as long as they can generate a
   proof.
   A few problems with this:
   - They often overestimate dependencies to make their proofs easier, and they consequently won't be
   able to remove some I/O events that actually semantically commute.
   - They still force themselves to stay on the original path through the state
   machine, i.e. they won't be able to find equivalent states that still
   violate the same invariant.
 - If we're going to really minimize inputs, we need to be willing to diverge
   from the original execution path. To do this, we need to be able to respond
   dynamically to I/O requests. In our case, the system that's going to do
   that response is a the mock network, which responds to clock value
   requests, and whose switches respond to messages.
 - We are, as far as we know, the first to minimize inputs by dynamically
   responding to the processes I/O requests. We show in the
   remainder of this paper that this works quite well
   empirically.
 - To get gaurentees on minimality, we could model checking / DPOR to exhaustively explore all thread
   interleavings for each subsequence tested by delta debugging.
 - This has problems foo, bar and baz.
 - As long as we're allowing ourselves to diverge then, we might as well get
   rid of the immense instrumentation, assumptions about language, and
   runtime overhead requirements of the other approaches that aren't very practical.
 - We therefore consider partial visibility, where we have
   visibility and control over message deliver events, but can't control the
   thread schedule, and don't have visibility into program flow. We then allow
   ourselves to proceed proceed forward despite unexpected or absent
   internal events.

Need to be added to the SIGCOMM paper:
  - New problem statement
  - Does it work with blackbox?
  - How well does it work when stopping whenever we observe unexpected events?
  - (already basically included:) how much non-determinism there was, i.e.
    what we needed to set max_replays_per_subsequence to.
  - Point out that we can crank out more synthetic bugs at the drop of a hat.
    Perhaps also point out why we didn't have more previously reported bugs
    (b/c SDN is too immature!)

Random insights:
- A scheduler for distributed processes (including interposing on the network) is really equivalent to a schedule
  on a single machine. The order messages are delivered (i.e. asynchrony) is
  encoded in the thread schedule.
- Practically speaking, mention that two (equivalent) states may exhibit the same bug. That's fine:
  just run it twice.
- IDEA: systematically/algorithmically explore levels of interposition. Start
  with blackbox, if that doesn't work, try with network interposition, etc.
  all the way up to DPOR.
