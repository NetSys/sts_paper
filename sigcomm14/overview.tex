In this section we review some of the key aspects of SDN systems, starting with the nature of the control plane and then the process of troubleshooting.

\subsection{SDN Control Planes}
Network operating systems, which are the key component of SDN software
infrastructure, consist of controller software running on a replicated set of
servers, each running a controller instance. The replicas typically use a
consensus protocol for leader election and a distributed database to store
state~\cite{onix}. Controllers receive input events and
statistics from switches (either physical or virtual), configuration and
policy changes via a management interface, and possibly packets from the data
plane. In response these events, the
controllers issue packet forwarding instructions to switches. All input
and output events are asynchronous, and individual controllers may fail at any
time. The controller instances may communicate
with each other over the network they manage, or use a separate dedicated
network. In either case, the controllers may become partitioned.

\subsection{Bugs, QA Testing, and Troubleshooting}
The goal of a network control plane is to configure the switch forwarding entries so as to
enforce one or more invariants, such as connectivity (\ie, ensuring that a
route exists between every endpoint pair), isolation and access control (\ie, various limitations on
connectivity), and virtualization (\ie, ensuring that packets are handled
in a manner consistent with what would happen in the specified virtual
network). A bug causes an invariant to be violated. Bugs can occur in the
configuration management system, \eg~OpenStack~\cite{quantum} (\ie, the
management system or a human improperly specified their goals), or it
can occur within the SDN control plane. In this paper we focus on bugs in the
SDN control plane after it has been given a configuration,
largely because the goal of SDN is to push complexity out of network management
and into the control plane.

In commercial SDN development, software developers work with a team of QA engineers whose
job it is to find bugs. The QA engineers run automated test scenarios that involve
sequences of external events such as failures, migrations, or policy changes
on large network testbeds (either real or emulated).
If they detect an invariant violation, they hand the resulting trace to a developer for analysis.

The space of possible bugs is enormous, and it is difficult and time
consuming to link the
symptom of a bug (\eg, a routing loop) to the sequence of events in the QA
trace (which includes both the external events and monitoring data on the
system itself), since QA traces contain a wealth
of extraneous input events, all of which may appear characteristic of normal
operating conditions at first glance. Consider that an hour long QA fuzz test
emulating event rates observed in production networks could contain 8.5 network error events per
minute~\cite{Greenberg:2009:VSF:1592568.1592576} and 500 VM migrations per
hour~\cite{Soundararajan:2010:CBS:1899928.1899941},
for a total of $8.5 \cdot 60 + 500 \approx 1000$ inputs.

The act of {\em troubleshooting} involves identifying which sequence of
external events is most directly responsible for triggering the bug;
identifying these events helps the developer in the act of {\em debugging},
\ie~understanding which code paths might
hold the offending code. Currently, painstaking manual analysis of logs is the {\em de facto} method of troubleshooting distributed systems in practice.
The smaller the sequence of triggering inputs, the easier debugging will
be. Minimizing the sequence of inputs is the goal of our system.

