Given a log $(E_L, T_L, C_L)$ exhibiting an invariant violation,
our goal is to identify its MCS. Achieving this goal involves two tasks:
searching for subsequences of $E_L$, and searching for replay timings for those
subsequences.

We illustrate the mechanics of our approach, \simulator, by describing an example bug in the Floodlight
open source control platform~\cite{floodlight_bug}. Floodlight is distributed across
multiple controllers for high availability, and provides support for
virtualization. Switches maintain one hot connection to a master controller and
several cold connections to replica controllers. The \emph{master} holds the
authority to modify the configuration of switches, while the other
controllers are in \emph{backup} mode and do not perform any changes to the
switch configurations unless they detect that the master has crashed.

\begin{figure}[t]
  %\hspace{-10pt}
  \includegraphics[width=3.25in]{../diagrams/case_study/example_bug.pdf}
  \caption[]{\label{fig:example} Floodlight failover bug. External inputs
             are depicted as red dots, internal events are depicted as black
             dots, and the dotted message line depicts a timeout.}
\end{figure}

The failover logic in Floodlight is not implemented correctly, leading to the
following race condition\footnote{Note that this issue was
originally documented by the developers of Floodlight~\cite{floodlight_bug}.} depicted in
Figure~\ref{fig:example}:
a link fails (E1), and the switch attempts to notify the controllers (E2,E4) shortly after the master
controller has died (E3), but before a new master has been selected (E6). In this case, all live controllers are in
the backup role and will not take responsibility for updating the switch
flow table (E5). At some point, a backup notices the master failure and
elevates itself to the master role (E6). The new master will proceed to manage
the switch, but without ever clearing the routing entries for
the failed link (resulting in a persistent blackhole). In this example, the MCS
is the conjunction of the two external inputs (E1,E3) in conjunction.

A developer or operator encountering this bug in practice would not be
given this concise version of events. Instead, the trace would contain a wealth
of extraneous inputs, making it difficult
to reason about the underlying root cause.
In the worst scenario, operators may need to examine logs from a production
network, which contain a substantial number of hardware failures, topology changes,
and other potential triggering events,
all of which may appear characteristic of normal operating
conditions at first glance; assuming 8.5 network error events per
minute~\cite{Greenberg:2009:VSF:1592568.1592576}, and 500 VM migrations per
hour~\cite{Soundararajan:2010:CBS:1899928.1899941},
there would be at least $8.5 \cdot 60 + 500 \approx 1000$ inputs reflected in
an hour-long trace.

\subsection{Searching for Subsequences}
\label{subsec:delta_debugging}

Checking random subsequences of $E_L$ would be one viable but inefficient
approach to achieving our first task. We can do better by leveraging a
divide-and-conquer search technique from the software engineering community:
the delta
debugging algorithm~\cite{Zeller:1999:YMP:318773.318946} provides a provably
correct means to isolating fault-inducing inputs. In our case, we use delta
debugging to iteratively select subsequences of $E_L$, replay each
subsequence with
some timing $T$, and check whether the bug persists. If the bug persists,
delta debugging ignores the
other inputs, and proceeds with the search for an MCS within this subsequence.
In what follows, we use the term {\em delta-debugging} to refer to our algorithm for finding relevant subsequences.
The delta debugging algorithm is shown in
Figure~\ref{fig:ddmin} (with `$test$' replaced by `$replay$').

It is worth noting that the input subsequences chosen by delta debugging are not always
valid. In particular, it is not sensible to replay a recovery event without a
preceding failure event; nor is it sensible to replay a host migration
event without modifying its starting position when a preceding host
migration event has been pruned. Our implementation of delta debugging therefore treats
failure/recovery events as atomic pairs, and updates initial host locations
whenever host migration events are pruned so that hosts do not appear at new
locations incongruously.\footnote{Handling invalid inputs is crucial for
ensuring that the delta debugging algorithm finds a minimal causal
subsequence. The algorithm we employ~\cite{Zeller:1999:YMP:318773.318946}
makes three
assumptions about inputs: monotonicity, unambiguity, and consistency.
Violating the first two only leads to slightly inflated MCSes. Zeller wrote a follow-on
paper~\cite{Zeller:2002:SIF:506201.506206} that removes the need for the
consistency assumption,
but incurs an additional factor of $N$ in complexity in doing so.}
These two heuristics account for validity of all network state change
events our system supports (shown in Table~\ref{tab:inputs}). We do not yet
support controller policy changes, which have more complex semantic
dependencies.


\begin{figure*}[t]
\caption{Automated Delta Debugging Algorithm From~\cite{Zeller:1999:YMP:318773.318946}}
\begin{boxedminipage}{\textwidth}
Input: $\cfail$ s.t. $\cfail$ is a trace and $\test(\cfail) = \DFAIL$. Output: $\dfail
= \ddmin(\cfail)$ s.t. $\dfail \subseteq
\cfail$, $\test(\dfail) = \DFAIL$, and~$\dfail$ is minimal.
\begin{align*}
\ddmin(\cfail) &= \ddmin_2(\cfail, \emptyset) \quad \text{where} \\
\ddmin_2(\dfail, R) &=
\begin{cases}
\dfail & \text{\hphantom{else }if $|\dfail| = 1$ (``base case'')} \\
\ddmin_2\bigl(\done, R\bigr) &
\text{else if $\test(\done \cup R) = \DFAIL$ (``in $\done$'')} \\
\ddmin_2\bigl(\dtwo, R\bigr) &
\text{else if $\test(\dtwo \cup R) = \DFAIL$ (``in $\dtwo$'')} \\
\ddmin_2\bigl(\done, \dtwo \cup R\bigr) \cup \ddmin_2\bigl(\dtwo, \done \cup
R\bigr) & \text{otherwise (``interference'')}
\end{cases}
\end{align*}
\begin{center}
where $\test(T)$ denotes the state of the system after executing the trace $T$,
$\DFAIL$ denotes a correctness violation, \\
$\done \subset \dfail$, $\dtwo \subset \dfail$, $\done \cup \dtwo = \dfail$, $\done \cap
\dtwo = \emptyset$, and $|\done| \approx |\dtwo| \approx |\dfail| / 2$
hold.
\end{center}
\end{boxedminipage}
\label{fig:ddmin}
\end{figure*}

\eat{ % Original O(n^2) algorithm
\begin{figure*}[t]
\caption{Minimizing Delta Debugging Algorithm From~\cite{Zeller:2002:SIF:506201.506206}}
\begin{boxedminipage}{\textwidth}
Input: $\cfail$ s.t. $\cfail$ is a trace and $\test(\cfail) = \FAIL$. Output: $\dfail
= \ddmin(\cfail)$ s.t. $\dfail \subseteq
\cfail$, $\test(\dfail) = \FAIL$, and~$\dfail$ is 1-minimal.
\begin{align*}
\ddmin(\cfail) &= \ddmin_2(\cfail, 2) \quad \text{where} \\
\ddmin_2(\dfail, n) &= 
\begin{cases}
\ddmin_2(\Delta_i, 2) & \text{\hphantom{else }if $\exists i \in \{1, \dots, n\} \cdot \test(\Delta_i) = \FAIL$ (``reduce to subset'')} \\
\ddmin_2\bigl(\nabla_i, \max(n - 1, 2)\bigr) & 
\text{else if $\exists i \in \{1, \dots, n\} \cdot \test(\nabla_i) = \FAIL$ (``reduce to complement'')} \\
\ddmin_2\bigl(\dfail, \min(|\dfail|, 2n)\bigr) & \text{else if $n < |\dfail|$ (``increase granularity'')} \\
\dfail & \text{otherwise (``done'').}
\end{cases}
\end{align*}
where $\test(T)$ denotes the state of the system after executing the trace $T$,
$\FAIL$ denotes a correctness violation, \\
$\nabla_i = \dfail - \Delta_i$, $\dfail = \Delta_1 \cup \Delta_2 \cup \dots \cup \Delta_n$, all
$\Delta_i$ are pairwise disjoint sequences of inputs, and $\forall \Delta_i \cdot |\Delta_i| \approx |\dfail| / n$
holds.
\end{boxedminipage}
\label{fig:ddmin}
\end{figure*}
}

\subsection{Searching for Timings}
\label{subsec:algorithm}

Simply exploring subsequences of $E_L$ does not suffice to find
minimal causal sequences: the
timing of those subsequences throughout invocations of $replay()$ is crucial for reliably
reproducing the
invariant violation. The most natural approach would be to maintain the original
timings, \ie~if we
define $t_i$ as the timestamp of the $i^{th}$ input from the original run and $t'_i$ as the
replay clock value when it injects that same input
(which may or may not be the $i$'th input in the subsequence), then we might
just set $t'_i = t_i$.
\eat{
\begin{align*}
t'_0 = t_0 \\
t'_i = t'_{i-1} + |t_{i} - t_{i-1}|
\end{align*}
}

Unfortunately, this approach does not work in practice because it can violate
causal dependencies. The crucial point here is that when we replay only a
subsequence of the original inputs, the reaction of the control software
can change, such that it behaves differently or takes a different amount of
time to respond to the remaining inputs events.
Simply maintaining relative timings might
result in injecting the remaining inputs too early or late.

Formally, to reliably reproduce the original invariant violation
we need to
inject an external input $e$ only after all other
events (both external and internal) that precede it in the
happens-before~\cite{Lamport:1978:TCO:359545.359563}
relation ($\{i \mid i \rightarrow e\}$) from the original execution have
occurred~\cite{tel2000introduction}. Internal events might include messages
sent between the controllers and switches, or state transitions within a single
controller. We can obtain the
happens-before relation in our logs by having our simulator
(to be described later) interpose on all message channels and
log a message only after all other logged messages have been delivered.

\subsection{Preserving Causality}

In practice it is non-trivial to reason about causal dependencies when transforming the original log
(which reproduces the violation) to a subsequence of external events
(which may or may not reproduce that violation).
To make progress we draw inferences about
the remaining causal dependencies in the subsequence based on the causal
dependencies reflected in the original log.
This involves three issues: coping with syntactic differences in internal
events across runs,
handling internal events from the original
execution that may not occur after pruning, and dealing with new internal events that were not
observed at all in the original execution.

\eat{
\colin{Somewhat redundant. Maybe wait until use cases.}
While the inputs and original internal events are given to us,
we become aware of new internal events throughout replay by
(i) monitoring
control message receipts between controllers and switches,
and (ii) interposing on the controllers' logging library and notifying the
simulator whenever the control software executes a log statement (which serve to mark relevant state
transitions). Note that to achieve truly deterministic
replay, these log statements would need to
be highly granular, capturing information such as thread scheduling decisions;
we show in \S\ref{subsec:case_studies}
however that pre-existing, course granular log statements are often sufficient to
successfully reproduce bugs.
}

%\footnote{We discuss this problem further in
%\S\ref{subsec:domain_knowledge}.}
%Note that the developer must provide enough logging statements
%so that relevant internal state changes are captured and visible to our
%tool.

{\bf Functional Equivalence: }The first issue is that internal events may differ syntactically (\eg~sequence numbers
of control packets may all differ) when replaying a subsequence of the original log.
We observe that many internal events are {\em functionally
equivalent}, in the sense that they
have the same effect on the state of the system with respect to triggering the
invariant violation (despite syntactic differences). For example, flow
modification messages may cause switches to make the same change to their forwarding behavior
even if the transaction identifier of the messages differ.

We leverage this observation by defining
domain-specific masks over semantically extraneous fields of
internal events.\footnote{One consequence
of applying masks is that bugs involving masked fields are outside the purview of
our approach.} These masks only need to be specified once, and can later be
applied programmatically to event traces.

We show the fields we mask in Table~\ref{tab:fingerprints}. We consider an internal event $i'$ observed in the subsequence log
equivalent (in the sense of inheriting all of its happens-before relations) to an internal event $i$ from the original log iff all unmasked
fields have the same value
and $i$ occurs between $i'$'s preceding and succeeding inputs in the
happens-before relation.

\begin{figure}[t]
    %\hspace{-10pt}
    \includegraphics[width=3.25in]{../diagrams/state_machines/controller_switch.pdf}
    \caption[]{\label{fig:state_machines} Simplified state machines for the switch and
    controllers in the example Floodlight bug. Double outlined states
    represent presence of the blackhole.}
\end{figure}

\begin{table}
\centering
\begin{tabular}{|l|l|}
\hline
Internal message & Masked values \\
\hline
\hline
OpenFlow messages & xac id, cookie, buffer id, stats \\
\hline
packet\_out/in payload & everything but src, dst, data \\
\hline
Log statements & varargs parameters to printf \\
\hline
\end{tabular}
\caption{Internal messages and their masked values. The masks serve to
define equivalence classes.}
\label{tab:fingerprints}
\end{table}

{\bf Handling Absent Internal Events:} Some internal events from the original log which causally ``happen before'' some external event
may be absent when replaying a subsequence of that log.
The structure of the control software's state machine (which we do not assume to know) determines whether
internal events disappear. Consider the simplified state machines for the switch and
controllers from the Floodlight case shown in
Figure~\ref{fig:state_machines}. If we prune the link failure input, the
master will never receive a link failure notification and
transition to and from `Send Flush'.

We handle this possibility by waiting for expected equivalent internal events,
but timing out and proceeding
if they do not occur within a certain time \textepsilon.
If the event scheduling algorithm detects that it has waited too long (such
that a happens-before successor has occurred before a predecessor), it
replays the log from the beginning up until the immediately prior input, this time
knowing which internal events in the current input interval are
and are not going to occur before injecting the next input. We show the overall event scheduling algorithm
in Figure~\ref{fig:peek}.

\begin{figure}
  \begin{pseudocode}[framebox]{CausalInference}{events}
    \PROCEDURE{Replay}{subsequence}
    \FOR e\textsubscript{i}\ in\ subsequence \\
    \BEGIN
    \IF e\textsubscript{i}\ is\ an\ internal\ event \\
    \AND e\textsubscript{i}\ is\ not\ marked\ absent:
    \THEN
    \BEGIN
      \Delta \GETS |e\textsubscript{i}.time - e\textsubscript{i-1}.time| + \epsilon \\
      wait\ up\ to\ \Delta\ seconds\ for\ e\textsubscript{i} \\
      \IF e\textsubscript{i}\ did\ not\ occur:
      \THEN mark\ e\textsubscript{i}\ as\ absent
    \END
    \ELSEIF e\textsubscript{i}\ is\ an\ input:
    \THEN
    \BEGIN
      \IF a\ successor\ of\ e\textsubscript{i}\ occurred: \\
      \INLINECOMMENT{waited too long}
      \THEN
        \RETURN{\CALL{Replay}{subsequence}}
      \ELSE
        inject\ e\textsubscript{i}
      \END
    \END
    \ENDPROCEDURE
  \end{pseudocode}
  \caption{{\tt Replay} is responsible for replaying subsequences of events
  chosen by delta debugging and determining
  if the bug reappears. \colin{Fix framebox width}}
    \label{fig:peek}
\end{figure}

{\bf Handling New Internal Events:}
The last possible change induced by input pruning is the occurrence of new
internal events that were not observed in the original log.
New events ultimately leave open multiple possibilities for where
we should inject the next input. Consider the following case:
if $i_2$ and $i_3$ are internal events observed
during replay that are both in the same equivalence class as a single event $i_1$ from the
original run, we could inject the next input after $i_2$ or after $i_3$.

% TODO: figure this figure out
%\begin{wrapfigure}{c}{1.3\linewidth}
%  \centering
%  \includegraphics[width=\linewidth,height=0.8in]{../diagrams/state_machines/event_sequence.pdf}
%\end{wrapfigure}

In the general case it is always possible to construct two state machines that lead
to differing outcomes: one that only leads to the invariant violation when
we inject the next input
before a new internal event, and one that only leads to the
invariant violation when we inject the next input after a new internal
event. In other words, to be guaranteed to traverse any existing suffix that leads
to the invariant violation, it is necessary to recursively branch, trying both
possibilities for every new internal event. This implies an exponential number of
possibilities to be explored in the worst case.

Exponential search over these possibilities is not a practical option. Our heuristic when waiting for expected internal
events is to proceed normally if there are intermediate new internal events,
always injecting the next input when its last expected predecessor
either occurs or times out. This ensures that we always find suffixes that
contain only a subset of the (equivalent) original internal events, but leaves open the
possibility of finding divergent suffixes that still lead to the invariant
violation.
%This is reasonable because not even branching on new
%internal events is guaranteed to find the globally shortest fault-inducing input
%sequence:
%there may be other unknown
%paths through the state machine leading to the invariant violation that are
%completely disjoint from the original execution.

\eat{
Luckily, crucially ambiguous new internal events are not problematic for the
control software we evaluated, as we show in \S\ref{sec:casestudies}.
We conjecture that ambiguous new internal events are
rare because SDN software is a control plane system,
and is designed to quiesce quickly (\ie~take a small number of internal
transitions after any input event, and stop at highly connected vertices).
Concretely, SDN programs are often structured as (mostly independent) event
handlers, meaning that pruning input events simply triggers a subset of the original
event handlers.
\eat{
As an illustration, consider the state machines
in Figure~\ref{fig:state_machines}:
the controllers quickly converge to a single state (either ``Master'' or
``Backup''), as do the switches (``Safe'').
}
}

\subsection{Complexity}
\label{subsec:complexity}

The delta debugging algorithm terminates after
$O(log\,n)$
invocations of $replay$ in the best case, where $n$ is the number of inputs in the original
trace~\cite{Zeller:1999:YMP:318773.318946}. In the worst case, delta debugging
has $O(n)$ complexity.

If the replay algorithm
never needs to back up, it replays $n$ inputs,
for an overall runtime of $O(nlog\,n)$ replayed inputs in the best case, and $O(n^2)$ in the worst case.
Conversely, if the event scheduling
needs to back up in every iteration, another factor of $n$ is added to the
runtime: for each input event
$e_i$, it replays inputs $e_1,\dots,e_i$, for a total of
$n \times \frac{n+1}{2} \in O(n^2)$ replayed inputs. In terms of replayed
inputs, the
overall worst case is therefore $O(n^3)$.

The runtime can be decreased by observing that delta debugging is readily
parallizable. Specifically, the worst case runtime could be
decreased to $O(n^2)$ by enumerating all subsequences that delta debugging
can possibly examine (of which there are $O(n)$), replaying them in parallel, and joining the
results.

The runtime can be further decreased by taking snapshots of the controller
state at regular intervals. When the replay algorithm detects that it has waited too
long, it could then restart from a recent snapshot rather than replaying the
entire prefix.

\eat{
SDN platform developers can reduce the probability that the replay algorithm
will need to back up by placing causal annotations on internal
events~\cite{fonseca2007x}: with explicit causal information, the replay
algorithm can know
\apriori~whether certain internal events are dependent on pruned inputs.
}

\colin{Describe Andrew's input type pruning optimization and measurements. "We
make another optimization.."}

In the next section we describe some
of the practical challenges we have overcome to realize our approach.
In our initial experiments we have found that applying delta debugging to explore
subsequences of $E_L$ and striving to maintain a single timing $T$ that maintains
causal dependencies reliably finds small MCSes.
