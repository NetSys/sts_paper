The scheduling heuristics we developed in the previous section have several
shortcomings. Most importantly, treating the software as a blackbox disallows us
from showing formal properties of the MCSes we produce. That is, we cannot
explain why our outputs are good approximations to truly minimal sequences, nor can we
explain how the heuristics helped. Second,
although we do not believe that the techniques are
specific to SDN control software, they currently pertain only to that specific
domain. Here we outline plans to address both of the these shortcomings.
At a high level, we plan to (i) start with an infeasible but provably correct
approach, and
(ii) find practical approximations to this approach, many of which will
involve leveraging empirical properties of (iii) different classes of distributed software
systems (beyond just SDN control software).

\noindent{\bf Showing Formal Properties of MCSes.} If we were to repeatedly
$replay$ a
fixed subsequence of external events $E_S$ to a blackbox distributed system,
it is possible that it would not to produce the same output on each
execution, even if we were to apply the heuristics outlined in
\S\ref{sec:past_work}. The issue is that we do not have full visibility into internal
events nor control over the internal scheduling decisions of the distributed
system. Our approach in~\cite{sts2014} was to
replay each subsequence multiple times, but this does not provide any
guarantees on the minimality of the MCSes we produce, since it's possible that
a subsequence $E_S$ that we thought did not reproduced the invariant violation
could have done so if the
distributed system had interleaved its internal events in some other way.

Suppose we want to show how close our outputs are to minimal. One approach would be to use a model checker to
{\em certify} whether each subsequence $E_S$ chosen by delta debugging does or
does not reproduce the original violation, thereby producing a provably
minimal MCS. The model checker could accomplish this
by systematically exploring all possible interleavings of internal events
given the fixed sequence of external events $E_S$.\footnote{Note that the
internal events are not fixed. That is, the schedule chosen by the model
checker affects which internal events are subsequently triggered by the software under
test.}

\noindent{\bf Working Around Impossibility.} In some cases, it is not possible for the model checker to certify a
given subsequence $E_S$. For example, suppose that the distributed system does
not terminate (or more specifically, suppose its state space is infinite
and non-recurring). In that case, model checking is not guaranteed to terminate.
Crucially, if the
model checker does not find a way to trigger the original violation in finite time,
that does not imply that the violation cannot be triggered, and we therefore lose our guarantees on minimality.

In distributed systems, non-termination means that an algorithm is not guaranteed to stop
sending messages. The formal term for this property is `non-quiescence`. In~\cite{aguilera1997heartbeat} Aguilera et al. prove that
all failure detectors---an important algorithmic component used by many distributed systems---are
non-quiescent.

As a fallback to non-quiescence, we can resort to
bounded model checking, where the model checker only explores the event
interleavings for a given subsequence $E_S$ up to a certain number of
execution steps. This approaches weakens the soundness (minimality) guarantees provided by
our approach in favor of the ability to operate on real distributed
systems implementations.

In some cases, we can also leverage the following observation to work around
non-quiescence:
given a failure detector component, it is possible to implement many other
distributed algorithms in a quiescent manner~\cite{aguilera1997heartbeat}. Building on this observation,
one might mark (non-quiescent) failure detector algorithms as `trusted-components`,
such that the model checker takes control of when the failure detector reports
failures and recoveries to the application, and systematically explores when
these failure/recovery reports are triggered in order to certify the remaining
(quiescent) components of the distributed system.

\noindent{\bf Making Certification Practical.} Although we only use the
model checker to find specific invariant violations rather than asking it to
find all invariant violations, it may nonetheless need to explore an
intractable number of event interleavings. This would make it impractical for
use on real distributed software.

We believe that we can ameliorate computational intractability by
leveraging the prior knowledge contained in the original failing test case.
That is, by making the $replay$ function stateful, we can develop heuristics that lead the
model checker to quickly find interleavings that trigger the original violation, so that
it is only forced to enumerate all interleavings for subsequence $E_S$ that do
not trigger the original violation.

As a concrete example, if we lead
the model checker to first explore interleavings that have small edit
distances from the original execution, we hypothesize that its probability of
finding the same invariant violation within the first few explored scheduled
will increase dramatically versus randomly choosing schedules to explore.
If the model checker can find violation-triggering schedules in $O(N)$ time rather than $O(2^N)$ time
(where $N$ denotes the number of events to schedule),
the asymptotic complexity of the overall minimization process can be reduced.
We will evaluate these heuristics empirically, by measuring the number of
interleavings that need to be explored for event traces where we know
MCS {\em a priori}. Often, we will develop these heuristics by examining the
behavior of specific distributed systems, as we describe next.

\noindent{\bf Applying to Other Distributed Systems.} In~\cite{sts2014} we
only applied our techniques to SDN control software. We do not however believe
that our techniques are specific to SDN. We have already begun applying our
techniques to other kinds of distributed systems, including distributed
databases and consensus protocols. One contribution of our work will be to
tailor our minimization strategies so that they
leverage the properties of those systems (e.g. atomic transactions in the
domain of distributed databases) or their empirical behavior (e.g. a tendency
to trigger violations along certain schedules) in
order to make the minimization process more practical.

% Left-behind ideas / lines of work:

% 1. exploring the "interposition tradeoff"? Iterate through the levels
% programmatically -- probably the case that different bug types necessitate
% different kinds of interposition. Also, look into modularizing model checking,
% a la JunFeng's work on demeter.

% 2. using Synoptic to generate model of the software.

% 3. Are Panda's email chains on modelling computational structure relevant?

% 4. Black-box delta debuggin on Jepsen.

% 5. Showing how to apply the techniques to production systems rather than QA
% tests.

% 6. Taint tracking / provenance

% 7. Dataflow analysis for filtering inputs. Possibly: dataflow analysis on
% network , but not controllers.

% 8. Optimizing delta debugging

% 9. Distinguishing between persistent and transient violations.

% 10. Using delta debugging to isolate differences, not just minimize whole test
